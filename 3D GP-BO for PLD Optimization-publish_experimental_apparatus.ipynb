{"cells":[{"cell_type":"markdown","metadata":{"id":"NsgAFgn-My7R"},"source":["# Setting up a 3D Bayesian optimization problem with gaussian process regression\n","\n","Jackson S. Bentley, Sumner B. Harris\n","09/01/25"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":809},"executionInfo":{"elapsed":10948,"status":"error","timestamp":1761250374650,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"I7r6X5vApoZd","outputId":"cb8cba55-f5eb-4e6e-bf5b-8f73b4b8e99a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: jax 0.7.2\n","Uninstalling jax-0.7.2:\n","  Successfully uninstalled jax-0.7.2\n","Found existing installation: jaxlib 0.7.2\n","Uninstalling jaxlib-0.7.2:\n","  Successfully uninstalled jaxlib-0.7.2\n","Found existing installation: ml_dtypes 0.5.3\n","Uninstalling ml_dtypes-0.5.3:\n","  Successfully uninstalled ml_dtypes-0.5.3\n","\u001b[33mWARNING: Skipping gpax as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting jax==0.6.2\n","  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n","Collecting jaxlib==0.6.2\n","  Downloading jaxlib-0.6.2-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Collecting ml_dtypes==0.5.1\n","  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from jax==0.6.2) (2.0.2)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.6.2) (3.4.0)\n","Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax==0.6.2) (1.16.2)\n","Downloading jax-0.6.2-py3-none-any.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jaxlib-0.6.2-cp312-cp312-manylinux2014_x86_64.whl (89.9 MB)\n","\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/89.9 MB\u001b[0m \u001b[31m184.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PackagePath' object has no attribute '_drv'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4207032675.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 2: Install compatible versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install jax==0.6.2 jaxlib==0.6.2 ml_dtypes==0.5.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Step 3: Install gpax version that supports jax>=0.6.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[0;32m--> 958\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     }\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mparts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m         \"\"\"An object providing sequence-like access to the\n\u001b[1;32m    705\u001b[0m         components in the filesystem path.\"\"\"\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_load_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_parse_path\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# e.g. //?/unc/server/share\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Step 1: Clean uninstall of conflicting packages\n","!pip uninstall -y jax jaxlib ml-dtypes gpax\n","\n","# Step 2: Install compatible versions\n","!pip install jax==0.6.2 jaxlib==0.6.2 ml_dtypes==0.5.1\n","\n","# Step 3: Install gpax version that supports jax>=0.6.2\n","!pip install gpax==0.1.9\n","\n","# Step 4: Force CPU use and test\n","import jax\n","import gpax\n","\n","jax.config.update(\"jax_platform_name\", \"cpu\")  # CPU only\n","gpax.utils.enable_x64()\n","\n","print(\"✅ GPAX is ready with JAX version:\", jax.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_-f29EyBK-C","executionInfo":{"status":"aborted","timestamp":1761250374653,"user_tz":240,"elapsed":28,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"}}},"outputs":[],"source":["# Define a degree symbol for later plotting\n","deg_sgn = '\\N{DEGREE SIGN}'\n"]},{"cell_type":"markdown","metadata":{"id":"vC0U85ldNQ5B"},"source":["# Define some functions for basic utilities\n","\n","I define some normalization functions and a function to package up data to save/load and plot results."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11040,"status":"aborted","timestamp":1761250374654,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"yj3V2EH0j7Ge"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib import rcParams, font_manager\n","import urllib.request\n","\n","font_url = \"https://github.com/google/fonts/raw/main/ofl/carlito/Carlito-Regular.ttf\"\n","font_path = \"/usr/share/fonts/truetype/Carlito-Regular.ttf\"\n","urllib.request.urlretrieve(font_url, font_path)\n","font_manager.fontManager.addfont(font_path)\n","\n","# List all fonts Matplotlib can see (optional, to verify Carlito is detected)\n","for f in font_manager.findSystemFonts(fontpaths=None, fontext='ttf'):\n","    if \"Carlito\" in f:\n","        print(f)\n","    if \"Carlito\" not in f:\n","        print('not there')\n","\n","# Set global font to Carlito\n","plt.rcParams['font.family'] = 'Carlito'\n","plt.rcParams['mathtext.fontset'] = 'custom'  # ensures math uses the same font family\n","plt.rcParams['mathtext.rm'] = 'Carlito'\n","plt.rcParams['mathtext.it'] = 'Carlito:italic'\n","plt.rcParams['mathtext.bf'] = 'Carlito:bold'\n","\n","alpha = 6.0606*2   # minmax: 6.0606; zscore: 23.6427 -- after B35, c=3.945\n","beta = 0.0876    # minmax: 0.0876; zscore: 0.3817  -- after B35\n","gamma = 4.3879   # minmax: 4.3879; zscore: 16.3955 -- after B35\n","delta = 0.0338   # minmax: 0.0338; zscore: 0.17   -- after B35\n","\n","# Normalize function (works for any number of dims)\n","def normalize(data, min_val, max_val):\n","    return (data - min_val) / (max_val - min_val)\n","\n","# Inverse normalization function\n","def inverse_normalize(norm_data, min_val, max_val):\n","    return norm_data * (max_val - min_val) + min_val\n","\n","def save_data(\n","    file_name,\n","    X_train, y_train,\n","    X_test,\n","    x1, x2, x3,           # now saving three parameter grids\n","    y_pred, y_sampled,\n","    acq, next_point,\n","    running_best,\n","    iteration\n","):\n","    np.savez(\n","        file_name,\n","        X_train=X_train,\n","        y_train=y_train,\n","        X_test=X_test,\n","        x1=x1,\n","        x2=x2,\n","        x3=x3,\n","        y_pred=y_pred,\n","        y_sampled=y_sampled,\n","        acq=acq,\n","        next_point=next_point,\n","        running_best=running_best,\n","        iteration=iteration\n","    )\n","\n","def load_data(file_name):\n","    ds = np.load(file_name, allow_pickle=True)\n","    return (\n","        ds['X_train'],\n","        ds['y_train'],\n","        ds['X_test'],\n","        ds['x1'],\n","        ds['x2'],\n","        ds['x3'],\n","        ds['y_pred'],\n","        ds['y_sampled'],\n","        ds['acq'],\n","        ds['next_point'],\n","        ds['running_best'],\n","        ds['iteration']\n","    )\n","\n","def update_datapoints(X_new, y_new, X_train, y_train):\n","    \"\"\"\n","    X_new: (N_samples, N_dims) normalized\n","    y_new: (N_samples,)\n","    \"\"\"\n","    X_train = jnp.append(X_train, X_new, axis=0)\n","    y_train = jnp.append(y_train, y_new, axis=0)\n","    return X_train, y_train\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_3d_projections(\n","    field_flat,      # 1D array of length nP * nT * nF\n","    P_array,         # 1D array of length nP (physical values)\n","    T_array,         # 1D array of length nT (physical values)\n","    F_array,         # 1D array of length nF (physical values)\n","    title: str,\n","    X_train: np.ndarray = None,  # shape (n_samples,3) in normalized space\n","    y_train: np.ndarray = None,  # shape (n_samples,)\n","    deg_sgn: str = '°',\n","    vmin=None,\n","    vmax=None\n","):\n","    \"\"\"\n","    Plot 3 projections (P vs T, P vs F, T vs F) of a 3D field,\n","    and scatter the measured X_train points colored by y_train.\n","    \"\"\"\n","    # Convert to numpy\n","    field = np.asarray(field_flat)\n","    nP, nT, nF = len(P_array), len(T_array), len(F_array)\n","    if field.size != nP * nT * nF:\n","        raise ValueError(f\"field length {field.size} != {nP}*{nT}*{nF}\")\n","\n","    # Reshape into 3D\n","    field3d = field.reshape(nP, nT, nF)\n","\n","    # Compute 2D projections\n","    proj_PT = field3d.mean(axis=2)  # shape (nP, nT)\n","    proj_PF = field3d.mean(axis=1)  # shape (nP, nF)\n","    proj_TF = field3d.mean(axis=0)  # shape (nT, nF)\n","\n","    # Set up subplots\n","    fig, axs = plt.subplots(1, 3, figsize=(18, 6), dpi=250, constrained_layout=True)\n","    # Set consistent tick label sizes for all subplots\n","    for ax in axs:\n","        ax.tick_params(axis='both', labelsize=12)\n","\n","    font_title = 22\n","    font_label = 18\n","    font_tick = 14\n","\n","\n","    # T vs P\n","    im0 = axs[0].pcolormesh(P_array, T_array, proj_PT.T, shading='auto', cmap='nipy_spectral', vmin=vmin, vmax=vmax)\n","    axs[0].set_xlabel('log$_{10}$ O$_2$ Partial Pressure (log$_{10}$ Torr)', fontsize=font_label)\n","    axs[0].set_ylabel(f'Deposition Temperature ({deg_sgn}C)', fontsize=font_label)\n","    axs[0].set_title(f'{title} → T vs P', fontsize=font_title)\n","    fig.colorbar(im0, ax=axs[0], orientation='vertical')\n","\n","    # F vs P\n","    im1 = axs[1].pcolormesh(P_array, F_array, proj_PF.T, shading='auto', cmap='nipy_spectral', vmin=vmin, vmax=vmax)\n","    axs[1].set_xlabel('log$_{10}$ O$_2$ Partial Pressure (log$_{10}$ Torr)', fontsize=font_label)\n","    axs[1].set_ylabel('Fluence (J/cm$^2$)', fontsize=font_label)\n","    axs[1].set_title(f'{title} → F vs P', fontsize=font_title)\n","    fig.colorbar(im1, ax=axs[1], orientation='vertical')\n","\n","    # F vs T\n","    im2 = axs[2].pcolormesh(T_array, F_array, proj_TF.T, shading='auto', cmap='nipy_spectral', vmin=vmin, vmax=vmax)\n","    axs[2].set_xlabel(f'Deposition Temperature ({deg_sgn}C)', fontsize=font_label)\n","    axs[2].set_ylabel('Fluence (J/cm$^2$)', fontsize=font_label)\n","    axs[2].set_title(f'{title} → F vs T', fontsize=font_title)\n","    fig.colorbar(im2, ax=axs[2], orientation='vertical')\n","\n","    # Scatter measured points colored by y_train\n","    if X_train is not None and y_train is not None:\n","        # Denormalize train points\n","        # Use different values than original script to inverse_normalize data, use values for normalization (below, pressure_min, pressure_max...)\n","        #P_train = inverse_normalize(X_train[:,0], P_array.min(), P_array.max())\n","        #T_train = inverse_normalize(X_train[:,1], T_array.min(), T_array.max())\n","        #F_train = inverse_normalize(X_train[:,2], F_array.min(), F_array.max())\n","        P_train = inverse_normalize(X_train[:,0], pressure_min, pressure_max)\n","        T_train = inverse_normalize(X_train[:,1], T_min, T_max)\n","        F_train = inverse_normalize(X_train[:,2], fluence_min, fluence_max)\n","        y_vals  = y_train.flatten()\n","\n","        # common scatter kwargs\n","        scatter_kwargs = dict(c=y_vals, cmap='Reds', edgecolor='k', s=200, alpha=0.8)\n","\n","        # P vs T\n","        sc0 = axs[0].scatter(P_train, T_train, **scatter_kwargs, vmin=0.3, vmax=3.1)\n","        #fig.colorbar(sc0, ax=axs[0], orientation='vertical', label='y_train')\n","\n","        # P vs F\n","        sc1 = axs[1].scatter(P_train, F_train, **scatter_kwargs, vmin=0.3, vmax=3.1)\n","        #fig.colorbar(sc1, ax=axs[1], orientation='vertical', label='y_train')\n","\n","        # T vs F\n","        sc2 = axs[2].scatter(T_train, F_train, **scatter_kwargs, vmin=0.3, vmax=3.1)\n","        #fig.colorbar(sc2, ax=axs[2], orientation='vertical', label='y_train')\n","\n","        # === Add shared colorbar next to the top-right of axs[2] ===\n","        from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n","\n","        # Create a small inset colorbar next to the title of the last subplot\n","        cbar_ax = inset_axes(\n","            axs[2],              # attach to third subplot (rightmost)\n","            width=\"60%\",          # width of colorbar\n","            height=\"5%\",        # height of colorbar\n","            loc='upper left',    # relative to the axis\n","            bbox_to_anchor=(0.55, 0.3, 1, 1),  # (x, y, width, height)\n","            bbox_transform=axs[2].transAxes,\n","            borderpad=0,\n","        )\n","\n","        cbar = fig.colorbar(sc0, cax=cbar_ax, orientation='horizontal')\n","        cbar.set_label('Sample\\nScores', fontsize=font_label)\n","        cbar.ax.tick_params(labelsize=font_tick)\n","\n","\n","\n","\n","    #fig.tight_layout()\n","    fig.suptitle(\n","    f\"{title}: Min-Max Scaling\\n\"\n","    r\"$y_{\\mathrm{train}} = \\alpha \\cdot |c - 3.945| + \\beta \\cdot R_{RMS} + \\gamma \\cdot FWHM + \\delta \\cdot LaVO_{4}$\" + \"\\n\" +\n","    f\"[α = {alpha}, β = {beta}, γ = {gamma}, δ = {delta}]\",\n","    fontsize=16,\n","    fontweight='bold',\n","    y=1.17\n","    )\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"ytLTgYOpNkw5"},"source":["# Set up the grid size"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11040,"status":"aborted","timestamp":1761250374655,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"OHnDPGpuDsqK"},"outputs":[],"source":["import numpy as np\n","\n","# --- Pressure (same as before) ---\n","start, stop = 3e-8, 3e-4\n","num_points_per_decade = 10\n","total_decades = int(np.log10(stop / start))\n","total_points = total_decades * num_points_per_decade + 1\n","\n","# log-space array (in decades) then take log to work in log-pressure\n","Pressure = np.log10(np.geomspace(start, stop, num=total_points))\n","pressure_min, pressure_max = Pressure.min(), Pressure.max()\n","\n","# --- Temperature (same as before) ---\n","T_min, T_max, T_stepsize = 500, 835, 20\n","Temperature = np.arange(T_min, T_max, T_stepsize, dtype=np.float32)\n","\n","# --- Fluence  ---\n","fluence_min, fluence_max, fluence_stepsize = 0.8, 2.2, 0.1\n","Fluence = np.arange(fluence_min, fluence_max, fluence_stepsize, dtype=np.float32)\n","\n","# --- Make normalized grids ---\n","P_norm = normalize(Pressure, pressure_min, pressure_max)\n","T_norm = normalize(Temperature, T_min, T_max)\n","F_norm = normalize(Fluence, fluence_min, fluence_max)\n","\n","# 3D meshgrid\n","Pg, Tg, Fg = np.meshgrid(P_norm, T_norm, F_norm, indexing='ij')\n","\n","# flatten each and stack into N×3 array\n","P_flat = Pg.reshape(-1, 1)\n","T_flat = Tg.reshape(-1, 1)\n","F_flat = Fg.reshape(-1, 1)\n","\n","points_3d = np.hstack((P_flat, T_flat, F_flat))\n","\n","print('3D parameter space has size:', points_3d.shape)\n","print('Pressure points:', Pressure.shape)\n","print('Temperature points:', Temperature.shape)\n","print('Fluence points:', Fluence.shape)\n","print('Back-transformed Pressure:', 10**(Pressure))\n"]},{"cell_type":"markdown","metadata":{"id":"Ez6X3rPrN5BJ"},"source":["# Initialize the noise and kernel lengthscale prior distributions and visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2l2No96EHke","executionInfo":{"status":"aborted","timestamp":1761250374655,"user_tz":240,"elapsed":11039,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"}}},"outputs":[],"source":["import numpyro\n","from numpyro import distributions\n","from jax import random\n","\n","# Define custom priors\n","lengthscale_prior_dist = distributions.LogNormal(-0.0, 1.0)\n","noise_prior_dist = distributions.HalfNormal(0.5)\n","#noise_prior_dist = distributions.LogNormal(0, 1)\n","#lengthscale_prior_dist = distributions.LogNormal(0, 1)\n","\n","rng_key = random.PRNGKey(0)\n","noise_dist = numpyro.sample(\"k_length\", noise_prior_dist,rng_key=rng_key, sample_shape=(1,10000))\n","length_dist = numpyro.sample(\"k_length\", lengthscale_prior_dist,rng_key=rng_key, sample_shape=(1,10000))\n","\n","#_ = plt.hist(length_dist,bins=500); plt.show()\n","#_ = plt.hist(noise_dist,bins=500); plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JZ1UEFjPOG5v"},"source":["# Set up code for each GP step\n","Here, we use variational inference GP with a Matern kernel.\n","\n","Currently, we're using the knowledge expected improvement function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_oki1btFvIt","executionInfo":{"status":"aborted","timestamp":1761250374656,"user_tz":240,"elapsed":11040,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"}}},"outputs":[],"source":["import jax.numpy as jnp\n","import jax\n","import gpax\n","\n","# enable 64-bit precision\n","gpax.utils.enable_x64()\n","\n","def step_GP(X_measured, y_measured, X_unmeasured,\n","            noise_prior_dist=None,\n","            lengthscale_prior_dist=None):\n","    \"\"\"Single GP step in 3D (T, P, Fluence).\"\"\"\n","    # 1) RNG keys\n","    rng_key1, rng_key2 = gpax.utils.get_keys()\n","\n","    # 2) Initialize a 3-dimensional GP\n","    gp_model = gpax.viGP(\n","        input_dim=3,\n","        kernel='Matern',\n","        noise_prior_dist=noise_prior_dist,\n","        lengthscale_prior_dist=lengthscale_prior_dist\n","    )\n","\n","    # 3) Fit via HMC\n","    print('Training Model.')\n","    gp_model.fit(rng_key1, X_measured, y_measured, jitter=1e-2)\n","\n","    # 4) Predict at all unmeasured points\n","    print('Getting Model Predictions.')\n","    y_pred, y_sampled = gp_model.predict_in_batches(\n","        rng_key2,\n","        X_unmeasured,\n","        noiseless=False,\n","        jitter=1e-2\n","    )\n","\n","    # 5) Compute Expected Improvement\n","    print('Calculating acquisition.')\n","    acquisition = gpax.acquisition.EI(\n","        rng_key2,\n","        gp_model,\n","        X_unmeasured,\n","        maximize=False,\n","        recent_points=X_measured,\n","        noiseless=False,\n","        jitter=1e-2,\n","        penalty='delta'\n","    )\n","\n","    # 6) (Optional) get posterior samples of hyperparameters\n","    print('Getting parameter samples.')\n","    paras = gp_model.get_samples()\n","\n","    return acquisition, y_pred, y_sampled, paras\n"]},{"cell_type":"markdown","metadata":{"id":"bm2pLJVUOfQo"},"source":["# Input initial seed points\n","\n","Here, I input your initial data save them to the \"BO_initial_data.npz\" file"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11040,"status":"aborted","timestamp":1761250374656,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"1THnOJ5rJ1U9"},"outputs":[],"source":["### --- Import all data here --- ###\n","import numpy as np\n","\n","from google.colab import files\n","\n","### --- Import all data here --- ###\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","# Load the Excel spreadsheet\n","file_path = '/content/LaVO3_PLD_Parameters_working_pressure_fixed_cleaned_up_no_10nm_no_LaVO4_to_B23.xlsx'  # Change this to your actual file path\n","#file_path = '/content/LaVO3_PLD_Parameters_cleaned_up_STO_no_10nm_SBH.xlsx'\n","sheet_name = 'Sheet1'         # Modify if your data is on a different sheet\n","\n","# Read the Excel file into a DataFrame\n","df = pd.read_excel(file_path, sheet_name=sheet_name)\n","\n","# Assume the unique sample identifiers are in a column called 'Sample ID' and so on\n","\n","sample_ids = df['Sample ID']\n","dates = df['Date (YYMMDD)']\n","substrates = df['Substrate']\n","fluence = df['Fluence (J/cm2)']\n","spot_size = df['Spot Size (mmxmm)']\n","o2_flow = df['O2 Flow (sccm)']\n","o2_pressure = df['O2 Pressure (Torr)']\n","working_pressure = df['Working pressure (Torr)']\n","base_pressure = df['Base Pressure (Torr)']\n","target = df['Target (1\")']\n","number_shots = df['Number Shots']\n","substrate_temp = df['Substrate Temp. (C) (based on average of temperature measured near substrate)']\n","rep_rate = df['Rep Rate (Hz)']\n","xrd = df['XRD']\n","xrr = df['XRR']\n","thickness_la_vo3 = df['Thickness (nm) (LaVO3 .cif, XRR)']\n","thickness_la_vo4 = df['Thickness (nm) (LaVO4, XRR)']\n","afm = df['AFM']\n","roughness = df['Roughness (nm) (standard deviation of height: 3x3 um, 2 Hz, 512 sam/l, B25 sub only = 0.147 )']\n","thickness_fringes = df['Thickness - fitting fringes (nm)']\n","c_lattice_parameter = df['C Lattice Parameter from Fringes (Å) (or 2Tw  peak position*)']\n","number_unit_cells = df['Number Unit Cells from Fringes']\n","thickness_per_shot = df['Thickness /shot from Fringes (nm/shot)']\n","rocking_curve = df['Rocking Curve']\n","fwhm_rocking_curve = df['FWHM (deg) (Gaussian fitting of rocking curve: B25: sub only, 1 twin=0.0050 )']\n","narrow_scan = df['Narrow Scan (43-51, 005, 2)']\n","integrated_intensity = df['Integrated LaVO4 Intensity: 48-51, normalized, x10^6 [B25 sub only= 4.7 (250520)]']\n","rsm = df['RSM']\n","\n","seed_points_raw = np.column_stack((o2_pressure, substrate_temp, fluence))\n","\n","\n","### --- Setup objective function --- ###\n","\n","lvo_c_lit = 3.945\n","\n","lattice_parameter_mismatch = np.abs(c_lattice_parameter - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * (roughness)\n","y_3 = gamma * (fwhm_rocking_curve)\n","y_4 = delta * (integrated_intensity)\n","y_train = (y_1 + y_2 + y_3 + y_4)\n","\n","# Normalize the seed points into [0,1] space\n","seed_points = np.zeros_like(seed_points_raw, dtype=np.float32)\n","# pressure: we normalize log-pressure\n","seed_points[:, 0] = normalize(np.log10(seed_points_raw[:, 0]), pressure_min, pressure_max)\n","# temperature:\n","seed_points[:, 1] = normalize(seed_points_raw[:, 1], T_min, T_max)\n","# fluence: normalize using your fluence bounds\n","seed_points[:, 2] = normalize(seed_points_raw[:, 2], fluence_min, fluence_max)\n","\n","X_train = seed_points\n","\n","# X_test should now be your full 3D grid, e.g. `points_3d` from before\n","X_test = points_3d\n","\n","# Save the initial data, now including x3=Fluence\n","file_name = \"BO_initial_data\"\n","save_data(\n","    file_name,\n","    X_train, y_train,\n","    X_test,\n","    x1=Pressure,\n","    x2=Temperature,\n","    x3=Fluence,\n","    y_pred=None,\n","    y_sampled=None,\n","    acq=None,\n","    next_point=None,\n","    running_best=100,\n","    iteration=0\n",")\n","\n","print('y_1, peak position:', y_1)\n","print('y_2, roughness:', y_2)\n","print('y_3, fwhm_rocking_curve:', y_3)\n","print('y_4, integrated_intensity:', y_4)\n","print('y_train:', y_train)\n","print()\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"Raw seed points:\\n\", seed_points_raw)\n","print(\"Any NaNs:\", np.isnan(y_train).any())\n","print(\"Any infs:\", np.isinf(y_train).any())\n","print(\"y_train range:\", y_train.min(), \"to\", y_train.max())\n","nan_mask = np.isnan(y_train)\n","\n","# Show indices of NaNs\n","nan_indices = np.where(nan_mask)[0]\n","print(\"Indices with NaN values in y_train:\", nan_indices)\n"]},{"cell_type":"markdown","metadata":{"id":"LVLNDs16OknQ"},"source":["# GP-BO Loop with EI acquisition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQW_y0XtuHVg","executionInfo":{"status":"aborted","timestamp":1761250374657,"user_tz":240,"elapsed":11040,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"}}},"outputs":[],"source":["def run_BO_step(previous_checkpoint_filename, X_new_unnormalized=None, y_new=None):\n","    # 1) Load your 3D data at the current step\n","    X_train, y_train, X_test, x1, x2, x3, \\\n","    y_pred, y_sampled, acq, next_point, \\\n","    running_best, iter = load_data(previous_checkpoint_filename)\n","\n","    # 2) (Optional) work in normalized y-space\n","    y_train_normalized = y_train\n","\n","    ##########------Update dataset with new value----###########\n","    if (X_new_unnormalized is not None and y_new is not None):\n","        iter += 1\n","        print('Updating dataset.')\n","        # normalize the new data points in each of the 3 dims\n","        X_new = np.zeros_like(X_new_unnormalized, dtype=np.float32)\n","        X_new[:, 0] = normalize(np.log10(X_new_unnormalized[:, 0]), pressure_min, pressure_max)\n","        X_new[:, 1] = normalize(X_new_unnormalized[:, 1], T_min, T_max)\n","        X_new[:, 2] = normalize(X_new_unnormalized[:, 2], fluence_min, fluence_max)\n","        print(X_train.shape,y_train.shape)\n","        print(X_new.shape, y_new.shape)\n","        X_train, y_train = update_datapoints(X_new, y_new, X_train, y_train)\n","\n","        # update running best if improved\n","        if y_new < running_best:\n","            print('Updating best data point.')\n","            running_best = y_new\n","\n","    print(f\"#######---Exploration step {iter}---#######\")\n","\n","    # 3) Fit GP and compute acquisition on the full 3D grid\n","    acq, y_pred, y_sampled, _params = step_GP(X_train, y_train, X_test)\n","\n","    # 4) Select the next sampling point\n","    next_idx = acq.argmax()\n","    X_next = X_test[next_idx].reshape(1, -1)\n","\n","    # 5) Current predicted best\n","    best_idx = y_pred.argmin()\n","    X_pred_best = X_test[best_idx].reshape(1, -1)\n","\n","    # 6) Optional stopping criterion\n","    if acq.max() < 0.01:\n","        print('%%%%%%%%%%%%%%% SUGGESTED STOPPING POINT %%%%%%%%%%%%%%%')\n","\n","    # 7) Save checkpoint (now including x3)\n","    result_file_path = f'BO_checkpoint_{iter}.npz'\n","    save_data(\n","        result_file_path,\n","        X_train, y_train, X_test,\n","        x1, x2, x3,\n","        y_pred, y_sampled, acq,\n","        next_point, running_best,\n","        iteration=iter\n","    )\n","\n","    # 8) Denormalize next & best points\n","    next_P = inverse_normalize(X_next[0, 0], pressure_min, pressure_max)\n","    next_T = inverse_normalize(X_next[0, 1], T_min, T_max)\n","    next_F = inverse_normalize(X_next[0, 2], fluence_min, fluence_max)\n","\n","    print(\n","        '%%%%%%%%% Next experiment %%%%%%%%%\\n'\n","        f'Pressure = {10**(next_P):.2e}, '\n","        f'Temperature = {next_T:.0f}, '\n","        f'Fluence = {next_F:.2e}'\n","    )\n","\n","    pred_best_P = inverse_normalize(X_pred_best[0, 0], pressure_min, pressure_max)\n","    pred_best_T = inverse_normalize(X_pred_best[0, 1], T_min, T_max)\n","    pred_best_F = inverse_normalize(X_pred_best[0, 2], fluence_min, fluence_max)\n","\n","    print(\n","        '%%%%%%%%% Current Predicted Best %%%%%%%%%\\n'\n","        f'Pressure = {10**(pred_best_P):.2e}, '\n","        f'Temperature = {pred_best_T:.0f}, '\n","        f'Fluence = {pred_best_F:.2e}'\n","    )\n","\n","    # 9) Current best measured point\n","    best_meas_idx = np.argmin(y_train.flatten())\n","    meas_best_P = inverse_normalize(X_train[best_meas_idx, 0], pressure_min, pressure_max)\n","    meas_best_T = inverse_normalize(X_train[best_meas_idx, 1], T_min, T_max)\n","    meas_best_F = inverse_normalize(X_train[best_meas_idx, 2], fluence_min, fluence_max)\n","    meas_best_y = y_train.flatten()[best_meas_idx]\n","\n","    print(\n","        '%%%%%%%%% Current Best Measured %%%%%%%%%\\n'\n","        f'Pressure = {10**(meas_best_P):.2e}, '\n","        f'Temperature = {meas_best_T:.0f}, '\n","        f'Fluence = {meas_best_F:.2e}, '\n","        f'y = {meas_best_y:.4f}'\n","    )\n","\n","    # 9) Plot the 3D results\n","    plot_3d_projections(\n","        y_pred, x1, x2, x3,\n","        title='GP Mean',\n","        X_train=X_train,\n","        y_train=y_train,\n","        vmin=0.5,\n","        vmax=2.5\n","    )\n","\n","    plot_3d_projections(\n","        y_sampled, x1, x2, x3,\n","        title='GP Variance',\n","        X_train=X_train,\n","        y_train=y_train,\n","        vmin=0.2,\n","        vmax=1.2\n","    )\n","\n","    plot_3d_projections(\n","        acq, x1, x2, x3,\n","        title='Acquisition',\n","        X_train=X_train,\n","        y_train=y_train,\n","        vmin=0,\n","        vmax=0.4\n","    )\n","    return result_file_path\n"]},{"cell_type":"markdown","metadata":{"id":"F1BPRW4YEaXt"},"source":["# Below is the optimization loop to run"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11034,"status":"aborted","timestamp":1761250374657,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"vI1DwDBsxQ-Z"},"outputs":[],"source":["# Load the data at the current step\n","# for the very first training, you need to load the initial data (seed points)\n","\n","previous_checkpoint_filename = '/content/BO_initial_data.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename) # give the GP the previous data\n","print('The results of this step are saved to a file named:', results_file)\n"]},{"cell_type":"markdown","metadata":{"id":"amUQnjnEFW4V"},"source":["# Now, go grow a sample with the suggested conditions, do XRD and AFM analyses, and enter it below"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11034,"status":"aborted","timestamp":1761250374658,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"8c2e6xncA0FE"},"outputs":[],"source":["### B24\n","\n","X_new = np.array([[1.8E-5, 715, 1.0]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.945 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.395\n","y_3 = gamma * 0.0361\n","y_4 = delta * 10.2\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_0.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"markdown","metadata":{"id":"pMZJz9MJJuPC"},"source":["# Go grow another sample"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11033,"status":"aborted","timestamp":1761250374658,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"KJ2R5IyoCfPf"},"outputs":[],"source":["### B25\n","\n","X_new = np.array([[2.1E-5, 720, 1.0]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.941 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.973\n","y_3 = gamma * 0.0387\n","y_4 = delta * 9.3\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_1.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"markdown","metadata":{"id":"NFGcdhKGKCQH"},"source":["# Go grow another sample"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11033,"status":"aborted","timestamp":1761250374659,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"quMASp2bKF9m"},"outputs":[],"source":["### B26\n","\n","X_new = np.array([[2.3E-7, 510, 0.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(4.041 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.303\n","y_3 = gamma * 0.0607\n","y_4 = delta * 8.6\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_2.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"markdown","metadata":{"id":"YZZUeNnsKuUZ"},"source":["# And so on..."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11032,"status":"aborted","timestamp":1761250374659,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"Z3DGC3MpKplU"},"outputs":[],"source":["### B27\n","\n","X_new = np.array([[4.4e-5, 815, 0.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.927 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 7.49\n","y_3 = gamma * 0.25\n","y_4 = delta * 33.7\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_3.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11043,"status":"aborted","timestamp":1761250374671,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"4uBSXAcSK1ay"},"outputs":[],"source":["### B28\n","\n","X_new = np.array([[2.2e-7, 535, 1.6]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(4.110 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.321\n","y_3 = gamma * 0.0432\n","y_4 = delta * 5.1\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_4.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11045,"status":"aborted","timestamp":1761250374673,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"y8iu_Nw7CyiH"},"outputs":[],"source":["### B29\n","\n","X_new = np.array([[3.6e-6, 655, 1.5]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.992 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.197\n","y_3 = gamma * 0.0463\n","y_4 = delta * 5.5\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_5.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11045,"status":"aborted","timestamp":1761250374673,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"JieBOAzjicM4"},"outputs":[],"source":["### B30\n","\n","X_new = np.array([[4e-7, 795, 0.83]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.965 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.183\n","y_3 = gamma * 0.0387\n","y_4 = delta * 5.1\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_6.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11044,"status":"aborted","timestamp":1761250374674,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"ZY_czkytjZg0"},"outputs":[],"source":["### B31\n","\n","X_new = np.array([[6e-6, 795, 0.83]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.935 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.237\n","y_3 = gamma * 0.0557\n","y_4 = delta * 8.5\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_7.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11043,"status":"aborted","timestamp":1761250374674,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"B5MXOeVwjcag"},"outputs":[],"source":["### B32\n","\n","X_new = np.array([[1e-6, 800, 0.83]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.9475 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.217\n","y_3 = gamma * 0.04\n","y_4 = delta * 6.1\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_8.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11044,"status":"aborted","timestamp":1761250374675,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"iBznUYiU9o5H"},"outputs":[],"source":["### A83\n","\n","X_new = np.array([[8.7e-5, 535, 1.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.98 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.397\n","y_3 = gamma * 0.0532\n","y_4 = delta * 4.6\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_9.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11044,"status":"aborted","timestamp":1761250374676,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"eFiqW19Jat8E"},"outputs":[],"source":["### B33\n","\n","X_new = np.array([[9.7e-5, 525, 0.83]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.943 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.182\n","y_3 = gamma * 0.0498\n","y_4 = delta * 4.6\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_10.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11043,"status":"aborted","timestamp":1761250374676,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"wUPZReKst3mP"},"outputs":[],"source":["### B34\n","\n","X_new = np.array([[2.1e-4, 510, 0.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.924 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 2.31\n","y_3 = gamma * 0.1766\n","y_4 = delta * 4.1\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_11.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11043,"status":"aborted","timestamp":1761250374677,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"B8VvqiZBt3Ww"},"outputs":[],"source":["### B35\n","\n","X_new = np.array([[1.4e-4, 635, 1.3]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.943 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 4.79\n","y_3 = gamma * 0.2548\n","y_4 = delta * 15.8\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_12.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11042,"status":"aborted","timestamp":1761250374677,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"J7sz_c-Zs9Oa"},"outputs":[],"source":["### B36\n","\n","X_new = np.array([[3.1e-5, 510, 0.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.9565 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.177\n","y_3 = gamma * 0.0518\n","y_4 = delta * 7.0\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_13.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11042,"status":"aborted","timestamp":1761250374677,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"1MUoS_P_zXXC"},"outputs":[],"source":["### B37\n","\n","X_new = np.array([[1.4e-6, 805, 0.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.9475 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.234\n","y_3 = gamma * 0.047\n","y_4 = delta * 6.2\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_14.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11042,"status":"aborted","timestamp":1761250374678,"user":{"displayName":"Jackson Bentley","userId":"02203350123197986530"},"user_tz":240},"id":"OXxzb9R_q5Tw"},"outputs":[],"source":["### B38\n","\n","X_new = np.array([[1.1e-6, 815, 0.8]]) # These are the conditions that you actually used for the growth\n","\n","lattice_parameter_mismatch = np.abs(3.947 - lvo_c_lit)\n","y_1 = alpha * lattice_parameter_mismatch\n","y_2 = beta * 0.225\n","y_3 = gamma * 0.0417\n","y_4 = delta * 6.2\n","y_new = (y_1 + y_2 + y_3 + y_4)\n","\n","\n","y_new = np.array([y_new])\n","#Shape needs to be (1,) not (1,1)\n","print('initial shape',y_new.shape)\n","\n","previous_checkpoint_filename = '/content/BO_checkpoint_15.npz'\n","\n","results_file = run_BO_step(previous_checkpoint_filename, X_new, y_new)# Give the GP the previous data, and the new data\n","print('The results of this step are saved to a file named:', results_file)"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[{"file_id":"15QM5htwgsQk8Cg_dA2H4c0i_6rCuoH92","timestamp":1752250967200},{"file_id":"1O0oYhBwW64wqKT3ib7Iln42EjStLGSt2","timestamp":1747315054527},{"file_id":"16z_yH2ut6N78wCj-Z10Aif_JqeKyz2m7","timestamp":1747313747772},{"file_id":"19MbsLkD9vc00SDBwJ1kvBlnUlkMh6368","timestamp":1739290602215},{"file_id":"1qM1ZN-2Eywd0bOsHFVq-EG1_fKsNKzMp","timestamp":1739283492615},{"file_id":"16daw7gsURCF02pDnQGQO1SpqM7E3UTTi","timestamp":1730925214104},{"file_id":"1wOnhX0BHn_rALo42EWQHq_0A4q4kjynP","timestamp":1730922426954},{"file_id":"1XYEZsBJwEVqRuA-sN3F7TeH6RDa6fRIP","timestamp":1730293596758}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}